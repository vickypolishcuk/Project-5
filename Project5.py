import lightgbm as lgb
import xgboost as xgb
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
import streamlit as st

# –ó—á–∏—Ç—É—î–º–æ –¥–∞–Ω—ñ –∑ —Ñ–∞–π–ª—É train
with open('train_data.txt', 'r', encoding='utf-8') as file:
    data = file.readlines()

# –†–æ–∑–¥—ñ–ª—è—î–º–æ –¥–∞–Ω—ñ –Ω–∞ —Ç–µ–∫—Å—Ç –≤—ñ–¥–≥—É–∫—É —ñ –º—ñ—Ç–∫—É –Ω–∞—Å—Ç—Ä–æ—é
X = [line.split(',', 1)[1].strip() for line in data]
y = [line.split(',')[0].strip() for line in data]

# –í–µ–∫—Ç–æ—Ä–∏–∑—É—î–º–æ —Ç–µ–∫—Å—Ç –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é TF-IDF
vectorizer = TfidfVectorizer(max_features=1000)
X_tfidf = vectorizer.fit_transform(X)

# –ó—á–∏—Ç—É—î–º–æ –¥–∞–Ω—ñ –∑ —Ñ–∞–π–ª—É test
with open('test_data.txt', 'r', encoding='utf-8') as file:
    data = file.readlines()

# –†–æ–∑–¥—ñ–ª—è—î–º–æ –¥–∞–Ω—ñ –Ω–∞ —Ç–µ–∫—Å—Ç –≤—ñ–¥–≥—É–∫—É —ñ –º—ñ—Ç–∫—É –Ω–∞—Å—Ç—Ä–æ—é
X_test = [line.split(',', 1)[1].strip() for line in data]
y_test = [line.split(',')[0].strip() for line in data]

# –í–µ–∫—Ç–æ—Ä–∏–∑—É—î–º–æ —Ç–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ
X_tfidf_test = vectorizer.transform(X_test)


@st.cache_resource
def train_GradientBoosting():
    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ —Ç–∞ –Ω–∞–≤—á–∞—î–º–æ –º–æ–¥–µ–ª—å –≥—Ä–∞–¥—ñ—î–Ω—Ç–Ω–æ–≥–æ –±—É—Å—Ç–∏–Ω–≥—É
    gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.01, max_depth=2, random_state=40)
    gb_classifier.fit(X_tfidf, y)

    # –ü—Ä–æ–≥–Ω–æ–∑—É—î–º–æ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
    y_pred = gb_classifier.predict(X_tfidf_test)

    # –û—Ü—ñ–Ω—é—î–º–æ —Ç–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ
    accuracy = accuracy_score(y_test, y_pred)
    print("Accuracy GradientBoosting:", accuracy)

    return gb_classifier


@st.cache_resource
def train_LightGBM():
    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ —Ç–∞ –Ω–∞–≤—á–∞—î–º–æ –º–æ–¥–µ–ª—å LightGBM
    gbm = lgb.LGBMClassifier(n_estimators=200, learning_rate=0.1, max_depth=2, min_child_samples=1, min_data_in_bin=1, random_state=40)
    gbm.fit(X_tfidf, y)

    # –ü—Ä–æ–≥–Ω–æ–∑—É—î–º–æ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
    y_pred = gbm.predict(X_tfidf_test)

    # –û—Ü—ñ–Ω—é—î–º–æ —Ç–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ
    accuracy = accuracy_score(y_test, y_pred)
    print("Accuracy LightGBM:", accuracy)

    return gbm


# –ü–µ—Ä–µ–∫–æ–¥—É—î–º–æ –º—ñ—Ç–∫–∏ –Ω–∞—Å—Ç—Ä–æ—é –≤ —á–∏—Å–ª–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
label_encoder = LabelEncoder()
y_encode = label_encoder.fit_transform(y)

@st.cache_resource
def train_XGBoost():
    dtrain = xgb.DMatrix(X_tfidf, label=y_encode)
    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ —Ç–∞ –Ω–∞–≤—á–∞—î–º–æ –º–æ–¥–µ–ª—å XGBoost
    params = {
        'objective': 'binary:logistic',  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –¥–ª—è –∑–∞–¥–∞—á –±—ñ–Ω–∞—Ä–Ω–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
        'max_depth': 3,
        'learning_rate': 0.1,
        'random_state': 10
    }
    bst = xgb.train(params, dtrain, num_boost_round=500)

    # –ü–µ—Ä–µ–∫–æ–¥—É—î–º–æ –º—ñ—Ç–∫–∏ –Ω–∞—Å—Ç—Ä–æ—é –≤ —á–∏—Å–ª–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
    y_test_encoded = label_encoder.transform(y_test)
    # –°—Ç–≤–æ—Ä–∏–º–æ –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏–π —Ç–∏–ø DMatrix –¥–ª—è XGBoost
    dtest = xgb.DMatrix(X_tfidf_test, label=y_test_encoded)
    # –ü—Ä–æ–≥–Ω–æ–∑—É—î–º–æ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
    y_pred_prob = bst.predict(dtest)
    y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]

    # –û—Ü—ñ–Ω—é—î–º–æ —Ç–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ
    accuracy = accuracy_score(y_test_encoded, y_pred)
    print("Accuracy XGBoost:", accuracy)

    return bst


@st.cache_resource
def train_RandomForest():
    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ —Ç–∞ –Ω–∞–≤—á–∞—î–º–æ –º–æ–¥–µ–ª—å Random Forest
    rf_classifier = RandomForestClassifier(n_estimators=300, max_depth=15, random_state=45)
    rf_classifier.fit(X_tfidf, y)

    # –ü—Ä–æ–≥–Ω–æ–∑—É—î–º–æ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
    y_pred = rf_classifier.predict(X_tfidf_test)

    # –û—Ü—ñ–Ω—é—î–º–æ —Ç–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ
    accuracy = accuracy_score(y_test, y_pred)
    print("Accuracy Random Forest:", accuracy)

    return rf_classifier


@st.cache_resource
def train_RandomForestRegressor():
    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ —Ç–∞ –Ω–∞–≤—á–∞—î–º–æ –º–æ–¥–µ–ª—å Random Forest
    rfr_classifier = RandomForestRegressor(n_estimators=300, max_depth=3,  random_state=45)
    rfr_classifier.fit(X_tfidf, y_encode)

    # –ü—Ä–æ–≥–Ω–æ–∑—É—î–º–æ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
    y_pred_prob = rfr_classifier.predict(X_tfidf_test)
    y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]

    # –ü–µ—Ä–µ–∫–æ–¥—É—î–º–æ –º—ñ—Ç–∫–∏ –Ω–∞—Å—Ç—Ä–æ—é –≤ —á–∏—Å–ª–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
    y_test_encoded = label_encoder.transform(y_test)

    # –û—Ü—ñ–Ω—é—î–º–æ —Ç–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ
    accuracy = accuracy_score(y_test_encoded, y_pred)
    print("Accuracy Random Forest Regressor:", accuracy)

    return rfr_classifier


# –ù–∞–≤—á–∞—î–º–æ –º–æ–¥–µ–ª—ñ
gb_classifier = train_GradientBoosting()
gbm = train_LightGBM()
bst = train_XGBoost()
rf_classifier = train_RandomForest()
rfr_classifier = train_RandomForestRegressor()


# –§—É–Ω–∫—Ü—ñ—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –Ω–∞—Å—Ç—Ä–æ—é –æ–∫—Ä–µ–º–æ—é –º–æ–¥–µ–ª–ª—é —Ç–∞ –∑–∞–≥–∞–ª–æ–º
def predict_sentiment(selected_model, user_input):
    # –í–µ–∫—Ç–æ—Ä–∏–∑—É—î–º–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏–π –≤–≤—ñ–¥
    user_input_tfidf = vectorizer.transform([user_input])

    # –í–∏–∫–æ–Ω—É—î–º–æ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è
    rf_pred = rf_classifier.predict(user_input_tfidf)[0]
    gb_pred = gb_classifier.predict(user_input_tfidf)[0]
    gbm_pred = gbm.predict(user_input_tfidf)[0]

    # –î–ª—è Random Forest Regressor —Ç–∞ XGBoost –∑–¥—ñ–π—Å–Ω—é—î–º–æ –Ω–µ–æ–±—Ö—ñ–¥–Ω—É –æ–±—Ä–æ–±–∫—É –≤—Ö—ñ–¥–Ω–∏—Ö —Ç–∞ –≤–∏—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö
    dtest_user = xgb.DMatrix(user_input_tfidf)
    bst_pred_prob = bst.predict(dtest_user)
    bst_pred = label_encoder.inverse_transform([1 if prob > 0.5 else 0 for prob in bst_pred_prob])[0]
    rfr_pred_prob = rfr_classifier.predict(user_input_tfidf)
    rfr_pred = label_encoder.inverse_transform([1 if prob > 0.5 else 0 for prob in rfr_pred_prob])[0]

    predictions = {
        "Random Forest": rf_pred,
        "Random Forest Regressor": rfr_pred,
        "GradientBoosting": gb_pred,
        "LightGBM": gbm_pred,
        "XGBoost": bst_pred
    }

    # –û–±—á–∏—Å–ª—é—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ü–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö —Ç–∞ –ù–µ–≥–∞—Ç–∏–≤–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å
    counts = {"–ü–æ–∑–∏—Ç–∏–≤–Ω–∏–π": 0, "–ù–µ–≥–∞—Ç–∏–≤–Ω–∏–π": 0}
    for pred in predictions.values():
        counts[pred] += 1
    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –∑–∞–≥–∞–ª—å–Ω–∏–π –Ω–∞—Å—Ç—Ä—ñ–π –≤—ñ–¥–≥—É–∫—É (–∑–∞ –≤—Å—ñ–º–∞ –º–æ–¥–µ–ª—è–º–∏)
    total_prediction = "–ü–æ–∑–∏—Ç–∏–≤–Ω–∏–π" if counts["–ü–æ–∑–∏—Ç–∏–≤–Ω–∏–π"] > counts["–ù–µ–≥–∞—Ç–∏–≤–Ω–∏–π"] else "–ù–µ–≥–∞—Ç–∏–≤–Ω–∏–π"

    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –≤–∏–±—Ä–∞–Ω—É –º–æ–¥–µ–ª—å
    if selected_model == "Random Forest":
        prediction = rf_pred
    elif selected_model == "Random Forest Regressor":
        prediction = rfr_pred
    elif selected_model == "GradientBoosting":
        prediction = gb_pred
    elif selected_model == "LightGBM":
        prediction = gbm_pred
    else:
        prediction = bst_pred
    return prediction, total_prediction


# –°—Ç–≤–æ—Ä—é—î–º–æ Streamlit –¥–æ–¥–∞—Ç–æ–∫
st.title("–ú–æ–¥–µ–ª—ñ –∞–Ω–∞–ª—ñ–∑—É –Ω–∞—Å—Ç—Ä–æ—é –≤—ñ–¥–≥—É–∫—ñ–≤")

# –†–æ–∑–¥—ñ–ª—è—î–º–æ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å –Ω–∞ 2 –∫–æ–ª–æ–Ω–∫–∏
col1, col2 = st.columns(2)

# –ó–∞–ø–æ–≤–Ω—é—î–º–æ –∫–æ–∂–Ω—É –∑ –∫–æ–ª–æ–Ω–æ–∫: 2 –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –∑–∞ –æ–±—Ä–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ, 1 - –∑–∞ –≤–≤–µ–¥–µ–Ω–Ω—è –≤—ñ–¥–≥—É–∫—É —Ç–∞ –≤–∏–≤–µ–¥–µ–Ω–Ω—è –π–æ–≥–æ –Ω–∞—Å—Ç—Ä–æ—é
with col2:
    select_model = st.radio("–í–∏–±–µ—Ä—ñ—Ç—å –º–æ–¥–µ–ª—å: üëá", ["Random Forest", "GradientBoosting", "LightGBM", "XGBoost", "Random Forest Regressor"])

with col1:
    user_input = st.text_input("–í–≤–µ–¥—ñ—Ç—å –≤—ñ–¥–≥—É–∫: ")
    if user_input:
        sentiment, total_sentiment = predict_sentiment(select_model, user_input)
        st.write(f"–ú–æ–¥–µ–ª–ª—é {select_model} –≤—ñ–¥–≥—É–∫ –≤–∏–∑–Ω–∞—á–µ–Ω–∏–π —è–∫: {sentiment}")
        st.write(f"–ó–∞–≥–∞–ª—å–Ω–æ –≤—ñ–¥–≥—É–∫ –≤–∏–∑–Ω–∞—á–µ–Ω–∏–π —è–∫: {total_sentiment}")


